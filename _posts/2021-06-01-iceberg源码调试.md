源码编译

```java
避免过多的checker信息
    将文件checkstyle.xml中的
    <module name="Checker">
      //....删除掉
    </module>

修改gradle的maven信息
	buildscript {
          repositories {
            maven{ url 'https://mirrors.huaweicloud.com/repository/maven/' }
            gradlePluginPortal()
          }
          ...
     }
     allprojects {
          group = "org.apache.iceberg"
          version = getProjectVersion()
          repositories {
            maven {
              url 'https://mirrors.huaweicloud.com/repository/maven/'
            }
            mavenCentral()
            mavenLocal()
          }
      }
修改gradle.properties修改编译flink的版本
	systemProp.defaultFlinkVersions=1.13
```

```java
iceberg流读编译

HiveConf hiveConf = new HiveConf();
String icebergNamespace = "icebergNamespace";
String icebergTableName = "icebergTableName";
TableIdentifier identifier = TableIdentifier.of(Namespace.of(icebergNamespace), icebergTableName);
HashMap<String, String> properties = new HashMap<>();
String icebergUri = "icebergUri";
properties.put("uri", icebergUri);
CatalogLoader catalogLoader = CatalogLoader.hive("hive", hiveConf, properties);
TableLoader tableLoader = TableLoader.fromCatalog(catalogLoader, identifier);

StreamExecutionEnvironment environment = StreamExecutionEnvironment.createLocalEnvironment();

DataStream<RowData> rowStream = FlinkSource.forRowData()
    .env(environment)
    .tableLoader(tableLoader)
    .streaming(true)
    .build();
```

```java
org.apache.iceberg.flink.source.FlinkSource.Builder
	构建FlinkSource

public static class FlinkSource.Builder {
    // todo flink stream 环境
    private StreamExecutionEnvironment env;
    // todo iceberg table
    private Table table;
    // todo 用于load iceberg表
    private TableLoader tableLoader;
    // todo iceberg 的schema描述
    private TableSchema projectedSchema;
    // todo 进行icebeg 表读取的配置参数
    private ReadableConfig readableConfig = new Configuration();
    // todo 构建scan 上下文(很关键); 能够进行filter/limit/properties设置/snapshotId指定, 是否区分大小写
    // todo datafile  split/数据回放 等
    private final ScanContext.Builder contextBuilder = ScanContext.builder();
}
```

```java
引用相关 Iceberg 接口和方法：

BaseTransaction.commitCreateTransaction()执行 tableOperation 事务
TableMetadataParser.write()写入元数据 json 文件
```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640095680496-ba273814-406f-493e-8839-70a51e83c594.png#clientId=u4a4d9a8f-259b-4&from=paste&height=189&id=ufda6da43&margin=%5Bobject%20Object%5D&name=image.png&originHeight=269&originWidth=511&originalType=binary&ratio=1&size=20678&status=done&style=none&taskId=ubc4a4e41-7bf7-415b-b7b0-b2a66df7fc6&width=359.5)

```java
在有多个IcebergStreamWriter和一个IcebergFileCommitter的情况下,上游的数据写到IcebergStreamWriter的时候,
每个Writer做的时间都是去写dataFiles文件。

当每个Writer写完自己当前这一批datafiles小文件的时候,就会发送消息给IcebergFileCommitter,告诉它可以提交了。
而IcebergFileCommitter收到信息的时候,就一次性将datafiles的文件提交,进行一次commit操作。

commit操作本身只是对一个原始信息的修改,当数据都已经写到磁盘了,只是让其从不可见变成可见。这种情况下,Iceberg只需要用一个
commit即可完成数据从不可见变成可见的过程。

```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640096926733-c1956ead-fa53-4080-b301-f381e89286c6.png#clientId=uc0bda46d-36d6-4&from=paste&height=240&id=ub8813510&margin=%5Bobject%20Object%5D&name=image.png&originHeight=480&originWidth=1322&originalType=binary&ratio=1&size=306626&status=done&style=none&taskId=uda371113-5688-45c7-9ca2-cd4f6db3df0&width=661)

```java
首先，如果有一个 write 操作，在写 snapsho-1 的时候，snapshot-1 是虚线框，也就是说此时还没有发生 commit 操作。
这时候对 snapshot-1 的读其实是不可读的，因为用户的读只能读到已经 commit 之后的 snapshot。
发生 commit 之后才可以读。同理，会有 snapshot-2，snapshot-3。

Iceberg 提供的一个重要能力, 就是读写分离能力。
 在对 snapshot-4 进行写的时候，其实是完全不影响对 snapshot-2 和 snapshot-3 的读。
 Iceberg 的这个能力对于构建实时数仓是非常重要的能力之一。

同理，读也是可以并发的，可以同时读 s1、s2、s3 的快照数据，这就提供了回溯读到 snapshot-2 或者 snapshot-3 数据的能力。
Snapshot-4 写完成之后，会发生一次 commit 操作，这个时候 snapshot-4 变成了实心，此时就可以读了。
另外，可以看到 current Snapshot 的指针移到 s4，也就是说默认情况下，
用户对一张表的读操作，都是读 current Snapshot 指针所指向的 Snapshot，但不会影响前面的 snapshot 的读操作。
```

mvcc&乐观并发

```java
一个表元数据文件与另一个表元数据文件的原子交换提供了可序列化的隔离。
读取器在加载表元数据时使用当前的快照,在刷新并拾取新的元数据位置之前不受更改的影响。
```
