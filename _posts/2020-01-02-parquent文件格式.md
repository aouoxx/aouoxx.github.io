---
layout: post
title: parquent文件格式
categories: [文件格式, parquent]
description: parquent文件格式
keywords: 文件格式, parquent
---

<meta name="referrer" content="no-referrer"/>

#### Parquet 的简介

```java
Parquet 是一种支持嵌套结构的列式存储格式
适用于OLAP场景, 按列存储和扫描


优势:
 1) 更高的压缩比
 	列式存储对每个列使用高效的压缩和编码,降低磁盘空间。 (压缩编码方式如: gzip,snappy)
 2) 更小的IO操作
 	使用映射下推和谓词下推,只读取需要的列,跳过不满足条件的列,减少不必要的数据扫描。

parquet是一种自解释的数据类型
 因为自身的内容包含对于自身结构的描述
```

> **_映射下推 vs 谓词下推_** > ** _ 映射下推: 列式存储最突出的优势, 指在获取数据时只需扫描需要的列，不用全部扫描_** > **_ 谓词下推: 通过一些过滤条件尽可能在最底层执行,以减少结果集。_** > **_ 谓词就是指这些过滤条件,即返回 bool: true 或 false 的表达式, 比如 SQL 中的大于小于等于、like、Is Null 等_**

#### 支持嵌套的数据模型

```java
Parquet 支持嵌套结构的数据模型, 而非扁平的数据模型, 这是parquet相对其他列存比如ORC的一大特点或优势。
支持嵌套结构,意味着Parquet能够很好的将诸如Protobuf, thrift, json等对象模型进行列式存储。

Parquet的数据模型也是schema表达方式, 用关键字message表示, 每个字段包含三个属性:
  >> repetition属性
        required/repeated/optional
  >> 数据类型
        primitive基本类型/group复杂类型
  >> 字段名


message AddressBook {
   required string owner;
   repeated string ownerPhoneNumbers;
   repeated group contacts {
      required string name;
      optional string phoneNumber;
   }
}

这个schema中每条纪录表示一个人的AddressBook, 有且只有一个owner, owner可以有0个或者多个ownerPhoneNumbers
owner可以有0个或者多个contacts。每个contact有且只有一个name, 这个contact的phoneNumber可有可无。

Parquet格式的数据类型没有复杂的Map,List,Set等,而是使用repeated fields和group来表示。
  例如 List和Set可以表示为一个repeated field,
		Map可以表示成一个包含有key-value的repeated field, 而且key是required的。


```

#### Parquet 格式的数据类型

```java
boolean    Abinaryvalue
int32  对应int类型
int64  对应long类型
int96
float
double
binary  sequence of 8-bit unsigned bytes
fixed_len_byte_array  A fixed number of 8-bit unsigned bytes
```

#### 存储模型

```java
这里存储模型又可以理解为存储格式或文件格式,
  parquet的存储模型主要由行组(Row Group),列快 (Column Chunk), 页(Page) 组成。


Row Group
	行组, parquet在水平方向上将数据划分为行组, 默认行组大小与HDFS Block块大小对齐,
    Parquet保证一个行组会被一个mapper处理

Column Chunk
	列块
	行组中每一列保存在一个列块中, 一个列块具有相同的数据类型,不同的列块可以使用不同的压缩

Paege
	页
    Parquet是页存储方式,每一个列块包含多个页,
	一个页是最小的编码的单位, 同一个列块不同页可以使用不同的编码方式
```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640856657913-6fce3f33-bf9a-4b71-8533-aabb0c288a82.png#clientId=u27047483-4a23-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=197&id=u24b759dd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=251&originWidth=371&originalType=binary&ratio=1&rotation=0&showTitle=false&size=14810&status=done&style=none&taskId=uaf113e4c-fc17-4af8-96c1-2ecc82de4a2&title=&width=290.5)
_**文件整体结构**_

![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640856680806-0d858a67-f527-42d7-8980-1a79b2e50c2c.png#clientId=u27047483-4a23-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=190&id=u948e57f1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=241&originWidth=791&originalType=binary&ratio=1&rotation=0&showTitle=false&size=29890&status=done&style=none&taskId=u6bc424b9-1160-4324-9266-23376f48908&title=&width=624.5)

_**文件内部结构**_
![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640856717906-3745371e-bdab-4494-9fb4-936a7cc999ef.png#clientId=u27047483-4a23-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=291&id=u7b603e29&margin=%5Bobject%20Object%5D&name=image.png&originHeight=348&originWidth=246&originalType=binary&ratio=1&rotation=0&showTitle=false&size=16697&status=done&style=none&taskId=uf8c52d22-40ab-4cef-bcf8-9572e663cbc&title=&width=206)![image.png](https://cdn.nlark.com/yuque/0/2021/png/659846/1640856745875-12b70971-02d2-49b0-8819-83002d891c6d.png#clientId=u27047483-4a23-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=237&id=u61b4bc22&margin=%5Bobject%20Object%5D&name=image.png&originHeight=291&originWidth=716&originalType=binary&ratio=1&rotation=0&showTitle=false&size=50464&status=done&style=none&taskId=u15da6609-6508-4533-a950-40358c4f8fa&title=&width=584)

```java
message t_staff_info_partition {
  optional int64 age;
  optional binary dt (UTF8);
  optional int64 id;
  optional binary name (UTF8);
  optional binary updated_time (UTF8);
}
```

#### parquet 的文件工具

```java
gaoshuoshuo381@hb16381 parquet % hdfs dfs -ls -h /user/gaoshuoshuo381
SLF4J: Class path contains multiple SLF4J bindings.
Found 3 items
drwx------   - gaoshuoshuo381 hadoop          0 2021-12-30 16:35 /user/gaoshuoshuo381/.Trash
drwx------   - gaoshuoshuo381 hadoop          0 2021-12-17 16:15 /user/gaoshuoshuo381/.flink
-rw-------   3 gaoshuoshuo381 hadoop        741 2021-12-30 16:44 /user/gaoshuoshuo381/tmp.parquet
gaoshuoshuo381@hb16381 parquet %
gaoshuoshuo381@hb16381 parquet %
gaoshuoshuo381@hb16381 parquet % hadoop jar parquet-tools-1.11.0.jar schema /user/gaoshuoshuo381/tmp.parquet
message Person {
  required binary name (STRING);
  required int32 age;
  repeated group House {
    required binary addr;
    optional int32 size;
  }
}

```

#### java 文件读写

```java
public class ParquetDemo {

    public static String content="message Person{\n" +
            " optional binary name (UTF8);\n" +
            " required int32 age;\n" +
            " repeated group House {\n" +
            "   required binary addr ;\n" +
            "   optional int32 size;\n" +
            "  }\n" +
            "}";

    public static void main(String[] args) throws Exception {
        read();
    }

    public static void read() throws Exception {
        GroupReadSupport readSupport = new GroupReadSupport();
        ParquetReader<Group> reader = new ParquetReader<Group>(new Path("hdfs://flashHadoopUAT/user/gaoshuoshuo381/tmp.parquet"),readSupport);
        Group line=null;
        while((line=reader.read())!=null){
            System.out.println(line.toString());
        }
        System.out.println("读取结束");
    }

    public static void write() throws Exception {
      MessageType schema =  MessageTypeParser.parseMessageType(content);
        GroupFactory factory = new SimpleGroupFactory(schema);
        Path path = new Path("hdfs://flashHadoopUAT/user/gaoshuoshuo381/tmp.parquet");
        Configuration configuration = new Configuration();
        GroupWriteSupport writeSupport = new GroupWriteSupport();
        writeSupport.setSchema(schema,configuration);
        ParquetWriter<Group> writer = new ParquetWriter<Group>(path,configuration,writeSupport);
        // //把本地文件读取进去，用来生成parquet格式文件
        for(int i=0;i<10;i++){
            Group group = factory.newGroup();
            if(i!=2){
                group.add("name","ssgao");
            }

            group.add("age",30);
            Group houseGroup1 = group.addGroup("House");
            if(i==3){
                houseGroup1.append("addr","hangzhou");
                houseGroup1.append("size",i);
                Group houseGroup2 = group.addGroup("House");
                houseGroup2.append("addr","hangzhou");
                houseGroup2.append("size",i);
            }else{
                houseGroup1.append("addr","hangzhou");
                houseGroup1.append("size",i);
            }

            writer.write(group);
        }
        writer.close();

    }
}
```

#### 底层 API

```java
Parquet 虽然支持很多编码方式, 但实际上Parquet只支持两种编码, PLAIN 和 Dictionary Encoding



ParquetProperties parquetProperties = ParquetProperties.builder()
            .withWriterVersion(writerVersion)
            .withPageSize(pageSize)
            .withDictionaryPageSize(dictionaryPageSize)
            .build();
```

#### parquet 编码方式

```java
Parquet支持的编码方式有很多中,实际上主要有两种,如 PLAIN 和 Dictionary Encoding。
只能设置开Dictionary或者不开Dictionary, 而且只能支持文件粒度的设置, 不支持列粒度的, 不能对某一具体的列设置编码

文件层API编码设置方式,初始化ParquetWriter时选择是否打开 DictionaryEncoding (enableDictionary参数)

```

> [_https://zhuanlan.zhihu.com/p/135188475_](https://zhuanlan.zhihu.com/p/135188475)

#### 底层代码和结构图

> [_https://www.cnblogs.com/mxxct/p/13857037.html_](https://www.cnblogs.com/mxxct/p/13857037.html) > [_https://www.cnblogs.com/windliu/p/10942252.html_](https://www.cnblogs.com/windliu/p/10942252.html)
